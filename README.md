# Blockwise-Parallel-Transformer-for-Long-Context-Large-Models
32 times longer context window than vanilla Transformers and up to 4 times longer than memory efficient Transformers.
